{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('MatchDB.db')\n",
    "df = pd.read_sql_query(\"SELECT * FROM Games WHERE League = 'Premier League' AND Country = 'ENG'\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['HomeTeam', 'AwayTeam', 'League', 'Country', 'date', 'id', 'match_id', 'HomexG', 'AwayxG'], axis=1)\n",
    "# df = df.drop(['AwayPoss', 'AwayShots', 'AwaySonT', 'AwaySoffT', 'AwayBS', 'AwayCor', 'AwayOff', 'AwayFoul', 'AwayYellow', 'AwayPass', 'AwayAccPass', 'AwayPassOff', 'AwayAccLongB', 'AwayAccLongBpercent', 'AwayAccCross', 'AwayAccCrosspercent', 'AwaySuccDribb', 'AwaySuccDribbpercent', 'AwayDuelsW', 'AwayTackW', 'AwayTackWpercent', 'AwayInt', 'AwayClear'], axis= 1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_values(row):\n",
    "    if row['HGoals'] > row['AGoals']:\n",
    "        return 0\n",
    "    elif row['AGoals'] > row['HGoals']:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "df['Winner'] = df.apply(compare_values, axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical \n",
    "prediction = df.drop(['HGoals', 'AGoals'], axis=1).astype(float)\n",
    "target_1 = df['Winner'].astype(float)\n",
    "\n",
    "target_1 = to_categorical(target_1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(prediction, target_1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = len(X_train.columns)\n",
    "input_shape = (n_cols,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# y_train = to_categorical(y_train)\n",
    "# y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "28/28 [==============================] - 2s 3ms/step - loss: 1.2569 - accuracy: 0.3960\n",
      "Epoch 2/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.9742 - accuracy: 0.5268\n",
      "Epoch 3/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.8744 - accuracy: 0.6286\n",
      "Epoch 4/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.8122 - accuracy: 0.6286\n",
      "Epoch 5/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7489 - accuracy: 0.6723\n",
      "Epoch 6/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.7356 - accuracy: 0.6846\n",
      "Epoch 7/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6806 - accuracy: 0.7159\n",
      "Epoch 8/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7125\n",
      "Epoch 9/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5929 - accuracy: 0.7383\n",
      "Epoch 10/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5558 - accuracy: 0.7584\n",
      "Epoch 11/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.5628 - accuracy: 0.7718\n",
      "Epoch 12/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8076\n",
      "Epoch 13/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.8221\n",
      "Epoch 14/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4123 - accuracy: 0.8221\n",
      "Epoch 15/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8389\n",
      "Epoch 16/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8591\n",
      "Epoch 17/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8736\n",
      "Epoch 18/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2761 - accuracy: 0.9038\n",
      "Epoch 19/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.3034 - accuracy: 0.8848\n",
      "Epoch 20/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2558 - accuracy: 0.8926\n",
      "Epoch 21/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2184 - accuracy: 0.9116\n",
      "Epoch 22/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8993\n",
      "Epoch 23/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.2117 - accuracy: 0.9251\n",
      "Epoch 24/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1645 - accuracy: 0.9396\n",
      "Epoch 25/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1586 - accuracy: 0.9463\n",
      "Epoch 26/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1380 - accuracy: 0.9575\n",
      "Epoch 27/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1425 - accuracy: 0.9530\n",
      "Epoch 28/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1560 - accuracy: 0.9430\n",
      "Epoch 29/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9586\n",
      "Epoch 30/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1484 - accuracy: 0.9396\n",
      "Epoch 31/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9564\n",
      "Epoch 32/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9687\n",
      "Epoch 33/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9385\n",
      "Epoch 34/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0993 - accuracy: 0.9743\n",
      "Epoch 35/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9866\n",
      "Epoch 36/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0522 - accuracy: 0.9843\n",
      "Epoch 37/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0668 - accuracy: 0.9821\n",
      "Epoch 38/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0534 - accuracy: 0.9821\n",
      "Epoch 39/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9765\n",
      "Epoch 40/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9743\n",
      "Epoch 41/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.9888\n",
      "Epoch 42/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9832\n",
      "Epoch 43/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1185 - accuracy: 0.9508\n",
      "Epoch 44/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0746 - accuracy: 0.9732\n",
      "Epoch 45/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0883 - accuracy: 0.9664\n",
      "Epoch 46/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0862 - accuracy: 0.9687\n",
      "Epoch 47/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9799\n",
      "Epoch 48/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9776\n",
      "Epoch 49/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0853 - accuracy: 0.9687\n",
      "Epoch 50/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1010 - accuracy: 0.9676\n",
      "Epoch 51/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1007 - accuracy: 0.9642\n",
      "Epoch 52/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0776 - accuracy: 0.9698\n",
      "Epoch 53/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.1039 - accuracy: 0.9620\n",
      "Epoch 54/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0946 - accuracy: 0.9676\n",
      "Epoch 55/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9732\n",
      "Epoch 56/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0749 - accuracy: 0.9698\n",
      "Epoch 57/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0501 - accuracy: 0.9843\n",
      "Epoch 58/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0304 - accuracy: 0.9911\n",
      "Epoch 59/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0311 - accuracy: 0.9877\n",
      "Epoch 60/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9911\n",
      "Epoch 61/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0347 - accuracy: 0.9877\n",
      "Epoch 62/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0381 - accuracy: 0.9866\n",
      "Epoch 63/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9843\n",
      "Epoch 64/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9799\n",
      "Epoch 65/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.9631\n",
      "Epoch 66/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 0.9855\n",
      "Epoch 67/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0421 - accuracy: 0.9877\n",
      "Epoch 68/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9899\n",
      "Epoch 69/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0898 - accuracy: 0.9653\n",
      "Epoch 70/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9888\n",
      "Epoch 71/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0644 - accuracy: 0.9810\n",
      "Epoch 72/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9866\n",
      "Epoch 73/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0807 - accuracy: 0.9676\n",
      "Epoch 74/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0714 - accuracy: 0.9765\n",
      "Epoch 75/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0452 - accuracy: 0.9799\n",
      "Epoch 76/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 0.9911\n",
      "Epoch 77/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0155 - accuracy: 0.9955\n",
      "Epoch 78/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0204 - accuracy: 0.9944\n",
      "Epoch 79/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0288 - accuracy: 0.9888\n",
      "Epoch 80/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0334 - accuracy: 0.9888\n",
      "Epoch 81/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0314 - accuracy: 0.9888\n",
      "Epoch 82/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0618 - accuracy: 0.9754\n",
      "Epoch 83/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9810\n",
      "Epoch 84/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0268 - accuracy: 0.9933\n",
      "Epoch 85/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9922\n",
      "Epoch 86/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 87/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 88/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0297 - accuracy: 0.9866\n",
      "Epoch 89/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9933\n",
      "Epoch 90/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0548 - accuracy: 0.9832\n",
      "Epoch 91/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0340 - accuracy: 0.9888\n",
      "Epoch 92/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9877\n",
      "Epoch 93/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0480 - accuracy: 0.9810\n",
      "Epoch 94/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0318 - accuracy: 0.9888\n",
      "Epoch 95/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 0.9911\n",
      "Epoch 96/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0278 - accuracy: 0.9933\n",
      "Epoch 97/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9955\n",
      "Epoch 98/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 99/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 100/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 101/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9989\n",
      "Epoch 102/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0283 - accuracy: 0.9933\n",
      "Epoch 103/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.9732\n",
      "Epoch 104/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0536 - accuracy: 0.9843\n",
      "Epoch 105/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9687\n",
      "Epoch 106/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9832\n",
      "Epoch 107/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9866\n",
      "Epoch 108/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9799\n",
      "Epoch 109/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0342 - accuracy: 0.9855\n",
      "Epoch 110/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 111/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0232 - accuracy: 0.9899\n",
      "Epoch 112/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9821\n",
      "Epoch 113/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9966\n",
      "Epoch 114/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 115/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9989\n",
      "Epoch 116/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0085 - accuracy: 0.9966\n",
      "Epoch 117/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9843\n",
      "Epoch 118/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9832\n",
      "Epoch 119/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9888\n",
      "Epoch 120/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9899\n",
      "Epoch 121/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9944\n",
      "Epoch 122/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 123/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0183 - accuracy: 0.9944\n",
      "Epoch 124/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9933\n",
      "Epoch 125/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9978\n",
      "Epoch 126/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 127/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9966\n",
      "Epoch 128/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0456 - accuracy: 0.9843\n",
      "Epoch 129/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0286 - accuracy: 0.9877\n",
      "Epoch 130/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0209 - accuracy: 0.9888\n",
      "Epoch 131/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0145 - accuracy: 0.9955\n",
      "Epoch 132/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0116 - accuracy: 0.9966\n",
      "Epoch 133/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9810\n",
      "Epoch 134/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9732\n",
      "Epoch 135/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0714 - accuracy: 0.9720\n",
      "Epoch 136/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9754\n",
      "Epoch 137/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9754\n",
      "Epoch 138/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0624 - accuracy: 0.9709\n",
      "Epoch 139/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9922\n",
      "Epoch 140/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0371 - accuracy: 0.9888\n",
      "Epoch 141/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0606 - accuracy: 0.9821\n",
      "Epoch 142/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0308 - accuracy: 0.9888\n",
      "Epoch 143/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9888\n",
      "Epoch 144/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0111 - accuracy: 0.9978\n",
      "Epoch 145/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0078 - accuracy: 0.9989\n",
      "Epoch 146/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 147/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9978\n",
      "Epoch 148/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0069 - accuracy: 0.9989\n",
      "Epoch 149/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0036 - accuracy: 1.0000\n",
      "Epoch 150/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 151/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 152/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 153/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9922\n",
      "Epoch 154/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0163 - accuracy: 0.9966\n",
      "Epoch 155/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 156/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9944\n",
      "Epoch 157/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9966\n",
      "Epoch 158/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 0.9978\n",
      "Epoch 159/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9877\n",
      "Epoch 160/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 0.9877\n",
      "Epoch 161/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 0.9944\n",
      "Epoch 162/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 0.9922\n",
      "Epoch 163/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 0.9966\n",
      "Epoch 164/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 165/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9978\n",
      "Epoch 166/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0121 - accuracy: 0.9944\n",
      "Epoch 167/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0158 - accuracy: 0.9944\n",
      "Epoch 168/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0396 - accuracy: 0.9810\n",
      "Epoch 169/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1309 - accuracy: 0.9620\n",
      "Epoch 170/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9799\n",
      "Epoch 171/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9955\n",
      "Epoch 172/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0087 - accuracy: 0.9966\n",
      "Epoch 173/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0162 - accuracy: 0.9922\n",
      "Epoch 174/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 175/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0114 - accuracy: 0.9944\n",
      "Epoch 176/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9955\n",
      "Epoch 177/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 178/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9933\n",
      "Epoch 179/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9765\n",
      "Epoch 180/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0895 - accuracy: 0.9664\n",
      "Epoch 181/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9843\n",
      "Epoch 182/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9810\n",
      "Epoch 183/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9978\n",
      "Epoch 184/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 185/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 186/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0222 - accuracy: 0.9888\n",
      "Epoch 187/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0172 - accuracy: 0.9966\n",
      "Epoch 188/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9955\n",
      "Epoch 189/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0118 - accuracy: 0.9966\n",
      "Epoch 190/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0319 - accuracy: 0.9899\n",
      "Epoch 191/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9676\n",
      "Epoch 192/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9899\n",
      "Epoch 193/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9978\n",
      "Epoch 194/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0093 - accuracy: 0.9978\n",
      "Epoch 195/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 196/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9978\n",
      "Epoch 197/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0048 - accuracy: 0.9989\n",
      "Epoch 198/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 199/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 200/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 0.9978\n",
      "Epoch 201/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 202/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9698\n",
      "Epoch 203/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0101 - accuracy: 0.9978\n",
      "Epoch 204/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0284 - accuracy: 0.9899\n",
      "Epoch 205/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9810\n",
      "Epoch 206/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0459 - accuracy: 0.9821\n",
      "Epoch 207/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9989\n",
      "Epoch 208/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0140 - accuracy: 0.9955\n",
      "Epoch 209/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 0.9944\n",
      "Epoch 210/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 211/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "Epoch 212/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0098 - accuracy: 0.9966\n",
      "Epoch 213/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 214/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 215/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 216/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 217/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 0.9978\n",
      "Epoch 218/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 0.9989\n",
      "Epoch 219/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 220/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 221/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9989\n",
      "Epoch 222/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 223/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 224/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 225/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 226/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 227/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 228/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 229/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 230/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 231/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0067 - accuracy: 0.9966\n",
      "Epoch 232/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9933\n",
      "Epoch 233/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0271 - accuracy: 0.9933\n",
      "Epoch 234/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0246 - accuracy: 0.9933\n",
      "Epoch 235/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.1085 - accuracy: 0.9687\n",
      "Epoch 236/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0743 - accuracy: 0.9664\n",
      "Epoch 237/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9687\n",
      "Epoch 238/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9866\n",
      "Epoch 239/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9922\n",
      "Epoch 240/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0190 - accuracy: 0.9944\n",
      "Epoch 241/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0198 - accuracy: 0.9922\n",
      "Epoch 242/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9989\n",
      "Epoch 243/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 244/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0062 - accuracy: 0.9989\n",
      "Epoch 245/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 0.9989\n",
      "Epoch 246/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 247/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 248/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0090 - accuracy: 0.9955\n",
      "Epoch 249/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 250/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 251/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 252/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9955\n",
      "Epoch 253/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 254/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.7889e-04 - accuracy: 1.0000\n",
      "Epoch 255/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.8685e-04 - accuracy: 1.0000\n",
      "Epoch 256/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 257/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9888\n",
      "Epoch 258/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9899\n",
      "Epoch 259/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.9922\n",
      "Epoch 260/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9933\n",
      "Epoch 261/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 0.9933\n",
      "Epoch 262/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0507 - accuracy: 0.9888\n",
      "Epoch 263/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9978\n",
      "Epoch 264/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 265/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0166 - accuracy: 0.9944\n",
      "Epoch 266/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9787\n",
      "Epoch 267/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0196 - accuracy: 0.9944\n",
      "Epoch 268/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9855\n",
      "Epoch 269/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 0.9955\n",
      "Epoch 270/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 271/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9966\n",
      "Epoch 272/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9955\n",
      "Epoch 273/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9978\n",
      "Epoch 274/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9978\n",
      "Epoch 275/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 0.9989\n",
      "Epoch 276/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7644e-04 - accuracy: 1.0000\n",
      "Epoch 277/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 278/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 279/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 280/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 281/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.5293e-04 - accuracy: 1.0000\n",
      "Epoch 282/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8915e-04 - accuracy: 1.0000\n",
      "Epoch 283/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 284/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 285/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 286/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0061 - accuracy: 0.9966\n",
      "Epoch 287/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9877\n",
      "Epoch 288/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0495 - accuracy: 0.9832\n",
      "Epoch 289/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9799\n",
      "Epoch 290/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0303 - accuracy: 0.9877\n",
      "Epoch 291/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9966\n",
      "Epoch 292/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0038 - accuracy: 0.9989\n",
      "Epoch 293/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0148 - accuracy: 0.9966\n",
      "Epoch 294/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9978\n",
      "Epoch 295/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 296/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 0.9966\n",
      "Epoch 297/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0405 - accuracy: 0.9888\n",
      "Epoch 298/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0194 - accuracy: 0.9944\n",
      "Epoch 299/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0180 - accuracy: 0.9955\n",
      "Epoch 300/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9911\n",
      "Epoch 301/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0251 - accuracy: 0.9944\n",
      "Epoch 302/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9955\n",
      "Epoch 303/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0118 - accuracy: 0.9944\n",
      "Epoch 304/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9989\n",
      "Epoch 305/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0115 - accuracy: 0.9944\n",
      "Epoch 306/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0838 - accuracy: 0.9787\n",
      "Epoch 307/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9799\n",
      "Epoch 308/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0524 - accuracy: 0.9821\n",
      "Epoch 309/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9978\n",
      "Epoch 310/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9955\n",
      "Epoch 311/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0046 - accuracy: 0.9978\n",
      "Epoch 312/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 313/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 314/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 315/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 316/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 317/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.5054e-04 - accuracy: 1.0000\n",
      "Epoch 318/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4867e-04 - accuracy: 1.0000\n",
      "Epoch 319/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.0041e-04 - accuracy: 1.0000\n",
      "Epoch 320/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.7972e-04 - accuracy: 1.0000\n",
      "Epoch 321/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.7290e-04 - accuracy: 1.0000\n",
      "Epoch 322/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.6632e-04 - accuracy: 1.0000\n",
      "Epoch 323/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 324/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8036e-04 - accuracy: 1.0000\n",
      "Epoch 325/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.6746e-04 - accuracy: 1.0000\n",
      "Epoch 326/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.9770e-04 - accuracy: 1.0000\n",
      "Epoch 327/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.0068e-04 - accuracy: 1.0000\n",
      "Epoch 328/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1921e-04 - accuracy: 1.0000\n",
      "Epoch 329/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.4282e-04 - accuracy: 1.0000\n",
      "Epoch 330/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.1272e-04 - accuracy: 1.0000\n",
      "Epoch 331/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.0840e-04 - accuracy: 1.0000\n",
      "Epoch 332/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.7236e-04 - accuracy: 1.0000\n",
      "Epoch 333/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 8.3903e-04 - accuracy: 1.0000\n",
      "Epoch 334/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.8434e-04 - accuracy: 1.0000\n",
      "Epoch 335/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 336/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.8304e-04 - accuracy: 1.0000\n",
      "Epoch 337/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6755e-04 - accuracy: 1.0000\n",
      "Epoch 338/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.3825e-04 - accuracy: 1.0000\n",
      "Epoch 339/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 340/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.2223e-04 - accuracy: 1.0000\n",
      "Epoch 341/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.5472e-05 - accuracy: 1.0000\n",
      "Epoch 342/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.6149e-04 - accuracy: 1.0000\n",
      "Epoch 343/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.5320e-04 - accuracy: 1.0000\n",
      "Epoch 344/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 0.9978\n",
      "Epoch 345/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9966\n",
      "Epoch 346/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0058 - accuracy: 0.9978\n",
      "Epoch 347/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 348/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 349/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9966\n",
      "Epoch 350/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9955\n",
      "Epoch 351/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9955\n",
      "Epoch 352/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9955\n",
      "Epoch 353/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0295 - accuracy: 0.9866\n",
      "Epoch 354/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0666 - accuracy: 0.9787\n",
      "Epoch 355/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9989\n",
      "Epoch 356/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 357/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9978\n",
      "Epoch 358/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9944\n",
      "Epoch 359/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0209 - accuracy: 0.9922\n",
      "Epoch 360/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0112 - accuracy: 0.9955\n",
      "Epoch 361/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 0.9966\n",
      "Epoch 362/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0201 - accuracy: 0.9911\n",
      "Epoch 363/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0093 - accuracy: 0.9966\n",
      "Epoch 364/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9944\n",
      "Epoch 365/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 366/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 367/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 368/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0050 - accuracy: 0.9978\n",
      "Epoch 369/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 370/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 371/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 7.8464e-04 - accuracy: 1.0000\n",
      "Epoch 372/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.1222e-04 - accuracy: 1.0000\n",
      "Epoch 373/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.4503e-04 - accuracy: 1.0000\n",
      "Epoch 374/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.5459e-04 - accuracy: 1.0000\n",
      "Epoch 375/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.9589e-04 - accuracy: 1.0000\n",
      "Epoch 376/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.0594e-04 - accuracy: 1.0000\n",
      "Epoch 377/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.8984e-04 - accuracy: 1.0000\n",
      "Epoch 378/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.7291e-04 - accuracy: 1.0000\n",
      "Epoch 379/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.2075e-04 - accuracy: 1.0000\n",
      "Epoch 380/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.4082e-04 - accuracy: 1.0000\n",
      "Epoch 381/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.3545e-04 - accuracy: 1.0000\n",
      "Epoch 382/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.0692e-04 - accuracy: 1.0000\n",
      "Epoch 383/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.4188e-04 - accuracy: 1.0000\n",
      "Epoch 384/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.4081e-04 - accuracy: 1.0000\n",
      "Epoch 385/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 8.2838e-04 - accuracy: 1.0000\n",
      "Epoch 386/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.3027e-04 - accuracy: 1.0000\n",
      "Epoch 387/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.2033e-04 - accuracy: 1.0000\n",
      "Epoch 388/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.1779e-04 - accuracy: 1.0000\n",
      "Epoch 389/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.0063e-04 - accuracy: 1.0000\n",
      "Epoch 390/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.8615e-04 - accuracy: 1.0000\n",
      "Epoch 391/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 5.8209e-04 - accuracy: 1.0000\n",
      "Epoch 392/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.0039e-04 - accuracy: 1.0000\n",
      "Epoch 393/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 394/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 9.1369e-04 - accuracy: 1.0000\n",
      "Epoch 395/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.4541e-04 - accuracy: 1.0000\n",
      "Epoch 396/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.2784e-04 - accuracy: 1.0000\n",
      "Epoch 397/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 3.1628e-04 - accuracy: 1.0000\n",
      "Epoch 398/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.6053e-04 - accuracy: 1.0000\n",
      "Epoch 399/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 4.7773e-04 - accuracy: 1.0000\n",
      "Epoch 400/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9955\n",
      "Epoch 401/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0401 - accuracy: 0.9866\n",
      "Epoch 402/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9877\n",
      "Epoch 403/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0750 - accuracy: 0.9743\n",
      "Epoch 404/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9933\n",
      "Epoch 405/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0239 - accuracy: 0.9933\n",
      "Epoch 406/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0348 - accuracy: 0.9855\n",
      "Epoch 407/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0112 - accuracy: 0.9966\n",
      "Epoch 408/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9978\n",
      "Epoch 409/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 0.9877\n",
      "Epoch 410/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9989\n",
      "Epoch 411/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 0.9966\n",
      "Epoch 412/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 413/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0039 - accuracy: 0.9978\n",
      "Epoch 414/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 415/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 9.7561e-04 - accuracy: 1.0000\n",
      "Epoch 416/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9966\n",
      "Epoch 417/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 418/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9978\n",
      "Epoch 419/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 0.9989\n",
      "Epoch 420/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0066 - accuracy: 0.9978\n",
      "Epoch 421/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9966\n",
      "Epoch 422/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0119 - accuracy: 0.9966\n",
      "Epoch 423/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0171 - accuracy: 0.9955\n",
      "Epoch 424/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0576 - accuracy: 0.9787\n",
      "Epoch 425/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9911\n",
      "Epoch 426/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0084 - accuracy: 0.9966\n",
      "Epoch 427/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 428/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9944\n",
      "Epoch 429/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0143 - accuracy: 0.9922\n",
      "Epoch 430/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0527 - accuracy: 0.9787\n",
      "Epoch 431/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0410 - accuracy: 0.9855\n",
      "Epoch 432/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9911\n",
      "Epoch 433/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 434/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9955\n",
      "Epoch 435/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0094 - accuracy: 0.9978\n",
      "Epoch 436/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0046 - accuracy: 0.9989\n",
      "Epoch 437/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 438/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.8505e-04 - accuracy: 1.0000\n",
      "Epoch 439/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.4148e-04 - accuracy: 1.0000\n",
      "Epoch 440/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.8141e-04 - accuracy: 1.0000\n",
      "Epoch 441/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 0.9989\n",
      "Epoch 442/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 443/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 444/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 445/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3761e-04 - accuracy: 1.0000\n",
      "Epoch 446/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0022 - accuracy: 0.9989\n",
      "Epoch 447/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 448/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 0.9966\n",
      "Epoch 449/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0080 - accuracy: 0.9989\n",
      "Epoch 450/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0077 - accuracy: 0.9978\n",
      "Epoch 451/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 452/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.0974e-04 - accuracy: 1.0000\n",
      "Epoch 453/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 5.3943e-04 - accuracy: 1.0000\n",
      "Epoch 454/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.0832e-04 - accuracy: 1.0000\n",
      "Epoch 455/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 2.8268e-04 - accuracy: 1.0000\n",
      "Epoch 456/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.1721e-04 - accuracy: 1.0000\n",
      "Epoch 457/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.0987e-04 - accuracy: 1.0000\n",
      "Epoch 458/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.1066e-04 - accuracy: 1.0000\n",
      "Epoch 459/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0030 - accuracy: 0.9989\n",
      "Epoch 460/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 461/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 462/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.1163 - accuracy: 0.9720\n",
      "Epoch 463/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0392 - accuracy: 0.9877\n",
      "Epoch 464/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 0.9877\n",
      "Epoch 465/500\n",
      "28/28 [==============================] - 0s 5ms/step - loss: 0.0089 - accuracy: 0.9989\n",
      "Epoch 466/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9955\n",
      "Epoch 467/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0122 - accuracy: 0.9978\n",
      "Epoch 468/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9955\n",
      "Epoch 469/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 470/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0037 - accuracy: 0.9989\n",
      "Epoch 471/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.9165e-04 - accuracy: 1.0000\n",
      "Epoch 472/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.4255e-04 - accuracy: 1.0000\n",
      "Epoch 473/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 8.8301e-04 - accuracy: 1.0000\n",
      "Epoch 474/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 7.7691e-04 - accuracy: 1.0000\n",
      "Epoch 475/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 476/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 0.9989\n",
      "Epoch 477/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.0625e-04 - accuracy: 1.0000\n",
      "Epoch 478/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 479/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.8285e-04 - accuracy: 1.0000\n",
      "Epoch 480/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 0.9978\n",
      "Epoch 481/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 6.7428e-04 - accuracy: 1.0000\n",
      "Epoch 482/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 3.4818e-04 - accuracy: 1.0000\n",
      "Epoch 483/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7887e-04 - accuracy: 1.0000\n",
      "Epoch 484/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.6863e-04 - accuracy: 1.0000\n",
      "Epoch 485/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.6885e-04 - accuracy: 1.0000\n",
      "Epoch 486/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.4125e-04 - accuracy: 1.0000\n",
      "Epoch 487/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5954e-04 - accuracy: 1.0000\n",
      "Epoch 488/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 4.8127e-04 - accuracy: 1.0000\n",
      "Epoch 489/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.5885e-04 - accuracy: 1.0000\n",
      "Epoch 490/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.7162e-04 - accuracy: 1.0000\n",
      "Epoch 491/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.3400e-04 - accuracy: 1.0000\n",
      "Epoch 492/500\n",
      "28/28 [==============================] - 0s 4ms/step - loss: 1.1946e-04 - accuracy: 1.0000\n",
      "Epoch 493/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 494/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 495/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 496/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 5.2872e-04 - accuracy: 1.0000\n",
      "Epoch 497/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.4262e-04 - accuracy: 1.0000\n",
      "Epoch 498/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 2.6459e-04 - accuracy: 1.0000\n",
      "Epoch 499/500\n",
      "28/28 [==============================] - 0s 3ms/step - loss: 1.0133e-04 - accuracy: 1.0000\n",
      "Epoch 500/500\n",
      "28/28 [==============================] - 0s 2ms/step - loss: 1.8012e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "lr_schedule = tensorflow.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "\n",
    "optimizer = tensorflow.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(250, activation = 'relu', input_shape = input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(200, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(3, activation = 'sigmoid'))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss', patience = 50)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "hist = model.fit(X_train, y_train,\n",
    "                 validation_split = 0.2,\n",
    "                 epochs = 500,\n",
    "                 callbacks = [early_stopping]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 0.9955\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[126], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39msqrt(hist\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m]), \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m plt\u001b[39m.\u001b[39mplot(np\u001b[39m.\u001b[39msqrt(hist\u001b[39m.\u001b[39;49mhistory[\u001b[39m'\u001b[39;49m\u001b[39mval_accuracy\u001b[39;49m\u001b[39m'\u001b[39;49m]), \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mEpochs\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m plt\u001b[39m.\u001b[39mylabel(\u001b[39m'\u001b[39m\u001b[39mValidation Loss\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'val_accuracy'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.sqrt(hist.history['accuracy']), 'r', label='Training accuracy')\n",
    "plt.plot(np.sqrt(hist.history['val_accuracy']), 'b', label='val_accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3959731459617615, 0.5268456339836121, 0.6286353468894958, 0.6286353468894958, 0.672259509563446, 0.6845637559890747, 0.7158836722373962, 0.7125279903411865, 0.7382550239562988, 0.7583892345428467, 0.7718120813369751, 0.8076062798500061, 0.8221476674079895, 0.8221476674079895, 0.8389261960983276, 0.8590604066848755, 0.8736017942428589, 0.9038031101226807, 0.8847874999046326, 0.8926174640655518, 0.9116331338882446, 0.899328887462616, 0.9250559210777283, 0.9395973086357117, 0.9463087320327759, 0.9574943780899048, 0.9530201554298401, 0.9429529905319214, 0.9586129784584045, 0.9395973086357117, 0.9563758373260498, 0.9686800837516785, 0.9384787678718567, 0.9742729067802429, 0.9865771532058716, 0.9843400716781616, 0.9821029305458069, 0.9821029305458069, 0.9765100479125977, 0.9742729067802429, 0.9888142943382263, 0.9832214713096619, 0.9507830142974854, 0.9731543660163879, 0.9664429426193237, 0.9686800837516785, 0.9798657894134521, 0.9776286482810974, 0.9686800837516785, 0.9675615429878235, 0.964205801486969, 0.9697986841201782, 0.9619686603546143, 0.9675615429878235, 0.9731543660163879, 0.9697986841201782, 0.9843400716781616, 0.991051435470581, 0.9876957535743713, 0.991051435470581, 0.9876957535743713, 0.9865771532058716, 0.9843400716781616, 0.9798657894134521, 0.963087260723114, 0.9854586124420166, 0.9876957535743713, 0.9899328947067261, 0.9653244018554688, 0.9888142943382263, 0.9809843301773071, 0.9865771532058716, 0.9675615429878235, 0.9765100479125977, 0.9798657894134521, 0.991051435470581, 0.9955257177352905, 0.9944071769714355, 0.9888142943382263, 0.9888142943382263, 0.9888142943382263, 0.9753915071487427, 0.9809843301773071, 0.9932885766029358, 0.9921700358390808, 1.0, 0.9955257177352905, 0.9865771532058716, 0.9932885766029358, 0.9832214713096619, 0.9888142943382263, 0.9876957535743713, 0.9809843301773071, 0.9888142943382263, 0.991051435470581, 0.9932885766029358, 0.9955257177352905, 0.998881459236145, 0.9966443181037903, 1.0, 0.998881459236145, 0.9932885766029358, 0.9731543660163879, 0.9843400716781616, 0.9686800837516785, 0.9832214713096619, 0.9865771532058716, 0.9798657894134521, 0.9854586124420166, 0.9932885766029358, 0.9899328947067261, 0.9821029305458069, 0.9966443181037903, 1.0, 0.998881459236145, 0.9966443181037903, 0.9843400716781616, 0.9832214713096619, 0.9888142943382263, 0.9899328947067261, 0.9944071769714355, 0.9966443181037903, 0.9944071769714355, 0.9932885766029358, 0.9977628588676453, 0.9966443181037903, 0.9966443181037903, 0.9843400716781616, 0.9876957535743713, 0.9888142943382263, 0.9955257177352905, 0.9966443181037903, 0.9809843301773071, 0.9731543660163879, 0.9720357656478882, 0.9753915071487427, 0.9753915071487427, 0.9709172248840332, 0.9921700358390808, 0.9888142943382263, 0.9821029305458069, 0.9888142943382263, 0.9888142943382263, 0.9977628588676453, 0.998881459236145, 1.0, 0.9977628588676453, 0.998881459236145, 1.0, 1.0, 1.0, 1.0, 0.9921700358390808, 0.9966443181037903, 1.0, 0.9944071769714355, 0.9966443181037903, 0.9977628588676453, 0.9876957535743713, 0.9876957535743713, 0.9944071769714355, 0.9921700358390808, 0.9966443181037903, 1.0, 0.9977628588676453, 0.9944071769714355, 0.9944071769714355, 0.9809843301773071, 0.9619686603546143, 0.9798657894134521, 0.9955257177352905, 0.9966443181037903, 0.9921700358390808, 0.9977628588676453, 0.9944071769714355, 0.9955257177352905, 0.9966443181037903, 0.9932885766029358, 0.9765100479125977, 0.9664429426193237, 0.9843400716781616, 0.9809843301773071, 0.9977628588676453, 0.9932885766029358, 0.9966443181037903, 0.9888142943382263, 0.9966443181037903, 0.9955257177352905, 0.9966443181037903, 0.9899328947067261, 0.9675615429878235, 0.9899328947067261, 0.9977628588676453, 0.9977628588676453, 1.0, 0.9977628588676453, 0.998881459236145, 1.0, 1.0, 0.9977628588676453, 1.0, 0.9697986841201782, 0.9977628588676453, 0.9899328947067261, 0.9809843301773071, 0.9821029305458069, 0.998881459236145, 0.9955257177352905, 0.9944071769714355, 0.9966443181037903, 0.9977628588676453, 0.9966443181037903, 0.998881459236145, 1.0, 1.0, 1.0, 0.9977628588676453, 0.998881459236145, 1.0, 1.0, 0.998881459236145, 1.0, 0.998881459236145, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9966443181037903, 0.9932885766029358, 0.9932885766029358, 0.9932885766029358, 0.9686800837516785, 0.9664429426193237, 0.9686800837516785, 0.9865771532058716, 0.9921700358390808, 0.9944071769714355, 0.9921700358390808, 0.998881459236145, 1.0, 0.998881459236145, 0.998881459236145, 0.9932885766029358, 0.9966443181037903, 0.9955257177352905, 1.0, 1.0, 0.998881459236145, 0.9955257177352905, 1.0, 1.0, 1.0, 1.0, 0.9888142943382263, 0.9899328947067261, 0.9921700358390808, 0.9932885766029358, 0.9932885766029358, 0.9888142943382263, 0.9977628588676453, 0.9966443181037903, 0.9944071769714355, 0.9787471890449524, 0.9944071769714355, 0.9854586124420166, 0.9955257177352905, 0.9966443181037903, 0.9966443181037903, 0.9955257177352905, 0.9977628588676453, 0.9977628588676453, 0.998881459236145, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9966443181037903, 0.9876957535743713, 0.9832214713096619, 0.9798657894134521, 0.9876957535743713, 0.9966443181037903, 0.998881459236145, 0.9966443181037903, 0.9977628588676453, 1.0, 0.9966443181037903, 0.9888142943382263, 0.9944071769714355, 0.9955257177352905, 0.991051435470581, 0.9944071769714355, 0.9955257177352905, 0.9944071769714355, 0.998881459236145, 0.9944071769714355, 0.9787471890449524, 0.9798657894134521, 0.9821029305458069, 0.9977628588676453, 0.9955257177352905, 0.9977628588676453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9977628588676453, 0.9966443181037903, 0.9977628588676453, 1.0, 1.0, 0.9966443181037903, 0.9955257177352905, 0.9955257177352905, 0.9955257177352905, 0.9865771532058716, 0.9787471890449524, 0.998881459236145, 1.0, 0.9977628588676453, 0.9944071769714355, 0.9921700358390808, 0.9955257177352905, 0.9966443181037903, 0.991051435470581, 0.9966443181037903, 0.9944071769714355, 0.9955257177352905, 1.0, 0.998881459236145, 0.9977628588676453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9955257177352905, 0.9865771532058716, 0.9876957535743713, 0.9742729067802429, 0.9932885766029358, 0.9932885766029358, 0.9854586124420166, 0.9966443181037903, 0.9977628588676453, 0.9876957535743713, 0.998881459236145, 0.9966443181037903, 1.0, 0.9977628588676453, 1.0, 1.0, 0.9966443181037903, 1.0, 0.9977628588676453, 0.998881459236145, 0.9977628588676453, 0.9966443181037903, 0.9966443181037903, 0.9955257177352905, 0.9787471890449524, 0.991051435470581, 0.9966443181037903, 1.0, 0.9944071769714355, 0.9921700358390808, 0.9787471890449524, 0.9854586124420166, 0.991051435470581, 1.0, 0.9955257177352905, 0.9977628588676453, 0.998881459236145, 1.0, 1.0, 1.0, 1.0, 0.998881459236145, 1.0, 1.0, 0.998881459236145, 1.0, 0.998881459236145, 1.0, 0.9966443181037903, 0.998881459236145, 0.9977628588676453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998881459236145, 1.0, 1.0, 0.9720357656478882, 0.9876957535743713, 0.9876957535743713, 0.998881459236145, 0.9955257177352905, 0.9977628588676453, 0.9955257177352905, 0.998881459236145, 0.998881459236145, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998881459236145, 1.0, 1.0, 1.0, 0.9977628588676453, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(hist.history['accuracy'])\n",
    "best_score = max(hist.history['accuracy'])\n",
    "# best_score2 = min(hist.history['val_loss'])\n",
    "print(best_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\simon\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('model_file.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
